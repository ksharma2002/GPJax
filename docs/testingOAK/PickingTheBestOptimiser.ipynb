{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "# Enable Float64 for more stable matrix inversions.\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import cola\n",
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jaxtyping import (\n",
    "    Array,\n",
    "    Float,\n",
    "    install_import_hook,\n",
    "    Num,\n",
    ")\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "import optax as ox\n",
    "\n",
    "with install_import_hook(\"gpjax\", \"beartype.beartype\"):\n",
    "    import gpjax as gpx\n",
    "from gpjax.typing import (\n",
    "    Array,\n",
    "    ScalarFloat,\n",
    ")\n",
    "from gpjax.distributions import GaussianDistribution\n",
    "from gpjax.kernels import AdditiveKernel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "# plt.style.use(\n",
    "#     \"https://raw.githubusercontent.com/JaxGaussianProcesses/GPJax/main/docs/examples/gpjax.mplstyle\"\n",
    "# )\n",
    "# colors = rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "cols = mpl.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "#imports AdditiveConjugatePosterior\n",
    "# from OAK import AdditiveConjugatePosterior\n",
    "from ChangingOptimiser import *\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "def calculate_nlpd(predictive_mean, predictive_stddev, actual_values):\n",
    "    variance = predictive_stddev ** 2\n",
    "    nlpd_sum = 0.5 * np.log(2 * np.pi * variance) + ((predictive_mean - actual_values) ** 2) / (2 * variance)\n",
    "    total_nlpd = np.sum(nlpd_sum)\n",
    "    return total_nlpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_optimiser(\n",
    "        D: gpx.Dataset = None,\n",
    "        optimiser_list: list[ox.GradientTransformation] = None, \n",
    "        num_iters = 100,\n",
    "        key: jr.PRNGKey = jr.PRNGKey(0),\n",
    "        noises = 0.01,\n",
    "        lengthscales = 1.0,\n",
    "        trainable_noise: bool = True,\n",
    "        ):\n",
    "    if not isinstance(num_iters, list):\n",
    "        if isinstance(num_iters, int):\n",
    "            num_iters = [num_iters]\n",
    "        else:\n",
    "            raise ValueError(\"num_iters should be a list of integers\")\n",
    "    if len(num_iters) == 1:\n",
    "        num_iters = num_iters * len(optimiser_list)\n",
    "    else:\n",
    "        assert len(num_iters) == len(optimiser_list), \"Number of iterations should be same as number of optimisers\"\n",
    "    \n",
    "    if not isinstance(noises, list):\n",
    "        if isinstance(noises, Union[float, int]):\n",
    "            noises = [noises]\n",
    "        else:\n",
    "            raise ValueError(\"Noises should be a list of floats or something like that\")\n",
    "    if len(noises) == 1:\n",
    "        noises = noises * len(optimiser_list)\n",
    "    else:\n",
    "        assert len(noises) == len(optimiser_list), \"Number of iterations should be same as number of optimisers\"\n",
    "\n",
    "    feature_dimension = X.shape[1]\n",
    "    number_of_optimisers = len(optimiser_list)\n",
    "\n",
    "    if not isinstance(lengthscales, list):\n",
    "        if isinstance(lengthscales, Union[float, int]):\n",
    "            lengthscales = [[float(lengthscales)]*feature_dimension]\n",
    "        else:\n",
    "            raise ValueError(\"num_iters should be a list of integers\")\n",
    "    if len(lengthscales) == 1:\n",
    "        lengthscales = lengthscales * len(optimiser_list)\n",
    "    else:\n",
    "        assert len(lengthscales) == len(optimiser_list), \"Number of iterations should be same as number of optimisers\"\n",
    "    for index in range(number_of_optimisers):\n",
    "        if isinstance(lengthscales[index], Union[float, int]):\n",
    "            lengthscales[index] = [lengthscales[index]] * feature_dimension\n",
    "        else:\n",
    "            assert len(lengthscales[index]) == feature_dimension, \"Lengthscales should be equal to feature dimension\"\n",
    "\n",
    "    # hi kishan\n",
    "\n",
    "    opt_posteriors = []\n",
    "    minimum_value = []\n",
    "    index = list(range(number_of_optimisers))\n",
    "\n",
    "    for i in range(number_of_optimisers):\n",
    "        noise = noises[i]\n",
    "        lengthscales_specific = lengthscales[i]\n",
    "        print(i)\n",
    "        meanf = gpx.mean_functions.Zero()\n",
    "        base_kernels = [gpx.kernels.RBF(active_dims=[j],\n",
    "            lengthscale=jnp.array(lengthscales_specific[j])\n",
    "            ) for j in range(feature_dimension)]\n",
    "        #base_kernels = [OrthogonalRBF(active_dims=[i], lengthscale=jnp.array([1.0])) for i in range(feature_dimension)]\n",
    "        likelihood = gpx.likelihoods.Gaussian(num_datapoints=D.n, obs_stddev=noise)\n",
    "        if not trainable_noise:\n",
    "            likelihood = likelihood.replace_trainable(obs_stddev=False)\n",
    "        obj = gpx.objectives.ConjugateLOOCV(negative=True)\n",
    "        maximum_interaction_depth = 2\n",
    "        kernel = AdditiveKernel(\n",
    "            kernels=base_kernels,\n",
    "            interaction_variances=jnp.array([1.0]*(maximum_interaction_depth + 1)) * jnp.var(D.y), \n",
    "            max_interaction_depth=maximum_interaction_depth, \n",
    "            )\n",
    "        prior = gpx.gps.Prior(mean_function=meanf, kernel=kernel)\n",
    "        posterior = AdditiveConjugatePosterior(prior =prior, likelihood=likelihood)\n",
    "        optimiser = optimiser_list[i]\n",
    "        num_iter = num_iters[i]\n",
    "        opt_posterior, history = gpx.fit(\n",
    "            model=posterior,\n",
    "            objective=obj,\n",
    "            train_data=D,\n",
    "            optim=optimiser,\n",
    "            num_iters=num_iter,\n",
    "            key=key, \n",
    "            safe=False,\n",
    "            verbose=False)\n",
    "        opt_posteriors.append(opt_posterior)\n",
    "        minimum_value.append(history[-1])       \n",
    "    values_to_return = sorted(zip(index,\n",
    "                                optimiser_list, \n",
    "                                opt_posteriors, \n",
    "                                minimum_value,\n",
    "                                noises, \n",
    "                                lengthscales\n",
    "                                ), key = lambda x: x[3])\n",
    "    print(\"Returning values\")\n",
    "    print(\"\\n\")\n",
    "    return values_to_return \n",
    "\n",
    "def best_optimiser_over_datasets(D: list[gpx.Dataset] = None,\n",
    "        optimiser_list: list[ox.GradientTransformation] = None, \n",
    "        num_iters = 100,\n",
    "        key: jr.PRNGKey = jr.PRNGKey(0),\n",
    "        noises = 0.01,\n",
    "        lengthscales = 1.0,\n",
    "        trainable_noise: bool = True,\n",
    "        ):\n",
    "    if not isinstance(D, list):\n",
    "        raise ValueError(\"D should be a list of datasets\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return x**2\n",
    "\n",
    "def f2(x):\n",
    "    return jnp.sin(x)\n",
    "\n",
    "def f3(x):\n",
    "    return jnp.cos(x**2) \n",
    "\n",
    "def f4(x):\n",
    "    return x**3\n",
    "\n",
    "def f5(x):\n",
    "    return jnp.exp(x)\n",
    "\n",
    "def f6(x):\n",
    "    return jnp.tanh(x)\n",
    "\n",
    "def f7(x):\n",
    "    return jnp.log(jnp.abs(x)+1)\n",
    "\n",
    "def f8(x):\n",
    "    return 0.5*x**2 + 0.2*x + 1\n",
    "\n",
    "def f9(x):\n",
    "    return 0.1*x**3 + 0.3*x**2 + 2*x + 1\n",
    "\n",
    "def f10(x):\n",
    "    return 0.1*x**4 + 0.5*x**3 + 1\n",
    "\n",
    "lof = [f1,f2,f3,f4,f5, f6, f7, f8, f9, f10]\n",
    "\n",
    "def f(x):\n",
    "    return sum([lof[i](x[:,i:i+1]) for i in range(len(lof))])\n",
    "\n",
    "n, noise = 400, 0.01\n",
    "key = jax.random.PRNGKey(np.random.randint(50))  # Replace 12345 with any desired seed value\n",
    "X = jr.uniform(key, (n, len(lof)))\n",
    "y = f(X) + jr.normal(key, (n, 1)) * noise\n",
    "#Select Data wanted\n",
    "X = jnp.array(X)\n",
    "# y = jnp.array(y).reshape(-1, 1) \n",
    "D = gpx.Dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Returning values\n",
      "\n",
      "\n",
      "Index: 3\n",
      "Minimum Value: -1297.5139108616438\n",
      "Index: 0\n",
      "Minimum Value: -1296.4733925103142\n",
      "Index: 4\n",
      "Minimum Value: -1296.3549298180199\n",
      "Index: 1\n",
      "Minimum Value: -1296.1153272670226\n",
      "Index: 5\n",
      "Minimum Value: -1296.0194085938574\n",
      "Index: 2\n",
      "Minimum Value: -1243.2194485265638\n"
     ]
    }
   ],
   "source": [
    "optimisers = [\n",
    "    ox.adam(1.0),\n",
    "    ox.adam(0.5),\n",
    "    ox.nadamw(1.0),\n",
    "    ox.nadamw(0.5),\n",
    "    ox.yogi(1.0),\n",
    "    ox.yogi(0.5),\n",
    "]\n",
    "\n",
    "num_iterations = 100\n",
    "noise = 0.01\n",
    "lengthscale = 1.0\n",
    "trainable_noise = True\n",
    "\n",
    "data_to_use = best_optimiser(\n",
    "    D=D,\n",
    "    optimiser_list= optimisers, \n",
    "    num_iters=num_iterations, \n",
    "    noises=noise,\n",
    "    lengthscales=lengthscale, \n",
    "    trainable_noise=trainable_noise\n",
    "    )\n",
    "\n",
    "for index, optimiser, opt_posterior, minimum_value, noise, lengthscales in data_to_use:\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Minimum Value: {minimum_value}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
